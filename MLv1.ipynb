{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas\n",
    "%pip install lazypredict\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path where the dataset is stored\n",
    "dataset_path = \"./input/crop-recommendation-dataset/Crop_Recommendation.csv\"\n",
    "\n",
    "# Check if the file exists before loading\n",
    "if os.path.exists(dataset_path):\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}. Please check the file path.\")\n",
    "\n",
    "# Splitting Features and Target Variable\n",
    "X = data.drop('Crop', axis=1)  # Features\n",
    "y = data['Crop']  # Target variable\n",
    "\n",
    "print(\"Data preview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Defines and builds the lazyclassifier\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models_train,predictions_train = clf.fit(X_train, X_train, y_train, y_train)\n",
    "models_test,predictions_test = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Prints the model performance\n",
    "models_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "\n",
    "import joblib\n",
    "\n",
    "model_filename = \"random_forest_model.pkl\"\n",
    "joblib.dump(rf, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(\"random_forest_model.pkl\")\n",
    "\n",
    "\n",
    "input = (160, 85, 59, 20, 30, 7.5, 70)  # Nitrogen, Phosphorous, Potassium, Temperature, Humidity, pH, Rainfall\n",
    "\n",
    "input_array = np.asarray(input)\n",
    "\n",
    "input_array_reshape = input_array.reshape(1, -1)\n",
    "\n",
    "predictions = model.predict(input_array_reshape)\n",
    "print (predictions)\n",
    "\n",
    "print(\"predictions are: \", predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (Make sure to update the correct path)\n",
    "dataset_path = \"./input/crop-recommendation-dataset/Crop_Recommendation.csv\"\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract the target variable (crop types)\n",
    "y = data['Crop']\n",
    "\n",
    "# Get the unique crop classes\n",
    "unique_classes = y.unique()\n",
    "\n",
    "# Count the number of unique crops\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "# Display the number of classes and their names\n",
    "print(f\"Number of crop classes: {num_classes}\")\n",
    "print(\"Crop classes:\")\n",
    "for crop in unique_classes:\n",
    "    print(\"-\", crop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENHANCED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset (ensure this path is correct)\n",
    "dataset_path = \"./input/crop-recommendation-dataset/Crop_Recommendation.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Plot the distribution of crops\n",
    "plt.figure(figsize=(12, 6))\n",
    "data['Crop'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Crop Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Crops in the Dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example input (change these values to test)\n",
    "input_data = np.array([[50, 40, 40, 30, 60, 6.5, 200]])  # Reshaped to (1, 7)\n",
    "\n",
    "# Predict probabilities for all 22 classes\n",
    "probabilities = rf.predict_proba(input_data)  # Get probability distribution\n",
    "\n",
    "# Get class names from dataset\n",
    "class_labels = data['Crop'].unique()\n",
    "\n",
    "# Display probabilities for each class\n",
    "print(\"Prediction Confidence for Each Crop:\")\n",
    "for crop, prob in zip(class_labels, probabilities[0]):\n",
    "    print(f\"{crop}: {prob:.4f}\")\n",
    "\n",
    "# Get the most probable crop\n",
    "predicted_crop = class_labels[np.argmax(probabilities)]\n",
    "print(f\"\\nFinal Prediction: {predicted_crop} (Confidence: {np.max(probabilities):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset (Make sure the path is correct)\n",
    "dataset_path = \"./input/crop-recommendation-dataset/Crop_Recommendation.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = data.drop(\"Crop\", axis=1)\n",
    "y = data[\"Crop\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Example input (modify values to test)\n",
    "input_data = np.array([[50, 40, 40, 30, 60, 6.5, 200]])  # Nitrogen, Phosphorous, Potassium, Temperature, Humidity, pH, Rainfall\n",
    "\n",
    "# Predict probabilities for all 22 classes\n",
    "probabilities = rf.predict_proba(input_data)  # Get probability distribution\n",
    "\n",
    "# Get class names from dataset\n",
    "class_labels = rf.classes_  # Use classes_ from trained model\n",
    "\n",
    "# Sort crops by confidence score (highest to lowest)\n",
    "sorted_indices = np.argsort(probabilities[0])[::-1]\n",
    "sorted_probs = probabilities[0][sorted_indices]\n",
    "sorted_labels = class_labels[sorted_indices]\n",
    "\n",
    "# Plot the confidence scores as a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(sorted_labels, sorted_probs, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Confidence Score\")\n",
    "plt.ylabel(\"Crop Type\")\n",
    "plt.title(\"Prediction Confidence for Each Crop\")\n",
    "plt.xlim(0, 1)  # Probabilities range from 0 to 1\n",
    "plt.gca().invert_yaxis()  # Flip so highest confidence is at the top\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the final prediction prominently\n",
    "predicted_crop = sorted_labels[0]\n",
    "confidence = sorted_probs[0]\n",
    "plt.annotate(f\"Predicted: {predicted_crop} ({confidence:.4f})\", xy=(confidence, 0), \n",
    "             xytext=(confidence - 0.2, 2), fontsize=12, color='red', fontweight='bold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import joblib\n",
    "\n",
    "# lazypredict may not be installed in all environments\n",
    "try:\n",
    "    import lazypredict\n",
    "except ImportError:\n",
    "    lazypredict = None\n",
    "\n",
    "print(\"Library Version Information:\")\n",
    "print(f\"panel: {pn.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"joblib: {joblib.__version__}\")\n",
    "if lazypredict:\n",
    "    print(f\"lazypredict: {lazypredict.__version__}\")\n",
    "else:\n",
    "    print(\"lazypredict: Not installed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
